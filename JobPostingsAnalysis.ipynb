{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c46e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/Job Hunting Tracking.xlsx'\n",
    "\n",
    "try:\n",
    "    # Use pandas to read the Excel file\n",
    "    # This will load the first sheet by default\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    df = df.iloc[:, :-3]\n",
    "    # Print a success message\n",
    "    print(\"Successfully loaded the Excel file into a DataFrame!\")\n",
    "\n",
    "    # Display the first 5 rows of the DataFrame to check the data\n",
    "    print(\"\\nHere are the first 5 rows of your data:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Display information about the DataFrame, like column names and data types\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()\n",
    "    \n",
    "    df['Job Posting Text'] = df['Job Posting Text'].str.replace(r'\\.net', 'dotnet', case=False, regex=True)\n",
    "    df['Job Posting Text'] = df['Job Posting Text'].str.replace(r'C#', 'csharp', case=False, regex=True)\n",
    "    df['Job Posting Text'] = df['Job Posting Text'].str.replace(r'C\\+\\+', 'cpp', case=False, regex=True)\n",
    "    \n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    print(\"Please make sure the Excel file is in the same directory as your Python script, or provide the full path to the file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Application Date'] = pd.to_datetime(df['Application Date'])\n",
    "\n",
    "# 2. Define your start date\n",
    "start_date = pd.to_datetime('5/13/2025')\n",
    "\n",
    "\n",
    "filtered_df = df[df['Application Date'] >= start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a966356",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_postings_text = filtered_df['Job Posting Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ed7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_postings_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text_for_topic_extraction(text):\n",
    "    \"\"\"\n",
    "    Cleans a single job posting text by:\n",
    "    1. Lowercasing the text.\n",
    "    2. Removing punctuation and numbers.\n",
    "    3. Tokenizing the text into words.\n",
    "    4. Removing stopwords.\n",
    "    5. Joining the cleaned words back into a string.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return empty string for non-string inputs (e.g., NaN)\n",
    "\n",
    "    # 1. Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove punctuation and numbers\n",
    "    # This regex keeps only letters and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # 3. Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # 4. Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1] # Also remove single character words\n",
    "\n",
    "    # 5. Join the cleaned words back into a string\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Apply the cleaning function to your 'Job Posting Text' series\n",
    "# Using .apply() is efficient for Series operations\n",
    "cleaned_job_posting_series = all_postings_text.apply(clean_text_for_topic_extraction)\n",
    "\n",
    "print(\"Original 'Job Posting Text' (head):\")\n",
    "print(all_postings_text.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Cleaned 'Job Posting Text' (head after stopword removal):\")\n",
    "print(cleaned_job_posting_series.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00795c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the canonical name and a list of variations to search for.\n",
    "# The search is case-insensitive, so we use lowercase.\n",
    "# We also handle special characters like '.' in '.net'.\n",
    "\n",
    "TECH_KEYWORDS = {\n",
    "    # Cloud & DevOps\n",
    "    'aws': ['aws', 'amazon web services'],\n",
    "    'azure': ['azure', 'microsoft azure'],\n",
    "    'gcp': ['gcp', 'google cloud'],\n",
    "    'docker': ['docker'],\n",
    "    'kubernetes': ['kubernetes', 'k8s'],\n",
    "    'terraform': ['terraform'],\n",
    "    'jenkins': ['jenkins'],\n",
    "    'kafka': ['kafka', 'apache kafka'],\n",
    "\n",
    "    # Backend Languages & Frameworks\n",
    "    'python': ['python'],\n",
    "    'java': ['java'],\n",
    "    'c#': ['csharp', '.net', 'dotnet'],\n",
    "    'c++': ['cpp'],\n",
    "    'go': ['go', 'golang'],\n",
    "    'ruby': ['ruby'],\n",
    "    'php': ['php'],\n",
    "    'node.js': ['node.js', 'nodejs'],\n",
    "    'django': ['django'],\n",
    "    'flask': ['flask'],\n",
    "    'spring': ['spring', 'spring boot'],\n",
    "    'laravel': ['laravel'],\n",
    "\n",
    "    # Frontend Languages & Frameworks\n",
    "    'javascript': ['javascript', 'js'],\n",
    "    'typescript': ['typescript', 'ts'],\n",
    "    'react': ['react', 'reactjs', 'react.js'],\n",
    "    'angular': ['angular', 'angularjs'],\n",
    "    'vue.js': ['vue', 'vuejs', 'vue.js'],\n",
    "    'html': ['html'],\n",
    "    'css': ['css'],\n",
    "\n",
    "    # Databases\n",
    "    'sql': ['sql'],\n",
    "    'mysql': ['mysql'],\n",
    "    'postgresql': ['postgresql', 'postgres'],\n",
    "    'mongodb': ['mongodb'],\n",
    "    'redis': ['redis'],\n",
    "\n",
    "    # Data Science & AI\n",
    "    'pandas': ['pandas'],\n",
    "    'numpy': ['numpy'],\n",
    "    'scikit-learn': ['scikit-learn', 'sklearn'],\n",
    "    'tensorflow': ['tensorflow'],\n",
    "    'pytorch': ['pytorch'],\n",
    "    'machine learning': ['machine learning', 'ml'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Use collections.Counter for efficient counting\n",
    "tech_counter = Counter()\n",
    "\n",
    "# Iterate through each cleaned job posting text\n",
    "for text in cleaned_job_posting_series:\n",
    "    # Use a set to track skills found in this specific post to avoid double-counting\n",
    "    found_in_this_post = set()\n",
    "\n",
    "    # Check for each canonical technology\n",
    "    for canonical_name, variations in TECH_KEYWORDS.items():\n",
    "        # Check all variations for that technology\n",
    "        for variation in variations:\n",
    "            # Use regex to find whole words only to avoid partial matches (e.g., 'java' in 'javascript')\n",
    "            # The `\\b` is a word boundary.\n",
    "            if re.search(r'\\b' + re.escape(variation) + r'\\b', text):\n",
    "                found_in_this_post.add(canonical_name)\n",
    "                break # Move to the next canonical name once a variation is found\n",
    "\n",
    "    # Update the main counter with the unique skills found in this post\n",
    "    tech_counter.update(found_in_this_post)\n",
    "\n",
    "# Convert the counter to a pandas DataFrame for better viewing and sorting\n",
    "tech_freq_df = pd.DataFrame(tech_counter.items(), columns=['Technology', 'Frequency'])\n",
    "tech_freq_df = tech_freq_df.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"Frequency of Technical Skills Mentioned in Job Postings:\")\n",
    "print(tech_freq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b23479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the counter to a pandas DataFrame for better viewing and sorting\n",
    "tech_freq_df = pd.DataFrame(tech_counter.items(), columns=['Technology', 'Frequency'])\n",
    "tech_freq_df = tech_freq_df.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# --- Display the results ---\n",
    "print(\"Frequency of Technical Skills Mentioned in Job Postings:\")\n",
    "print(tech_freq_df)\n",
    "\n",
    "# --- SAVE THE OUTPUT TO A CSV FILE (New line) ---\n",
    "tech_freq_df.to_csv('data/technical_skills_frequency.csv', index=False)\n",
    "\n",
    "print(\"\\nSuccessfully saved the frequency count to 'technical_skills_frequency.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
